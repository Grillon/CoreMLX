# CoreMLX
## Core ML eXtensible

**Chatbot local, modulaire et Ã©volutif** â€” conÃ§u pour servir de socle libre Ã  des dÃ©monstrations MLOps, DevOps, Docker et CI/CD.

## ğŸ¯ Objectif

CrÃ©er un systÃ¨me dâ€™infÃ©rence local basÃ© sur un modÃ¨le prÃ©entraÃ®nÃ© encapsulÃ© dans une API compatible OpenAI, avec une interface utilisateur simple. Le tout doit Ãªtre modulaire, documentÃ©, exÃ©cutable en local et Ã©volutif vers des fonctionnalitÃ©s avancÃ©es (RAG, fine-tuning, observabilitÃ©).

## ğŸ§± Architecture (Phase 1)

- `backend/` â†’ FastAPI exposant `/v1/chat/completions`
- `model/` â†’ wrapper autour dâ€™un modÃ¨le local (e.g. `llama.cpp`, `phi-2`)
- `frontend/` â†’ Streamlit, interface de chat simple

## âœ… Avancement

Phase 1 en cours :
- [x] Structuration projet
- [ ] Choix du modÃ¨le
- [ ] Backend minimal
- [ ] Frontend simple
- [ ] Pitch + vidÃ©o de dÃ©monstration

## ğŸ”“ Licence

MIT â€” rÃ©utilisable librement avec attribution.

## ğŸ”— Liens (Ã  venir)

- DÃ©mo vidÃ©o
- Documentation technique
- PrÃ©sentation pÃ©dagogique
